version: '3.8'

services:
  financial-analysis-mcp:
    build: .
    container_name: financial-analysis-mcp
    environment:
      - PYTHONPATH=/app
      - PYTHONUNBUFFERED=1
    volumes:
      # Mount output directory for generated analysis files
      - ./output:/app/output
      # Mount .env file if it exists
      - ./.env:/app/.env:ro
    stdin_open: true
    tty: true
    # For MCP stdio transport, we typically don't need port mapping
    # ports:
    #   - "8000:8000"

  # Optional: If you want to run with Ollama locally
  # ollama:
  #   image: ollama/ollama:latest
  #   container_name: ollama
  #   ports:
  #     - "11434:11434"
  #   volumes:
  #     - ollama_data:/root/.ollama
  #   environment:
  #     - OLLAMA_ORIGINS=*

# volumes:
#   ollama_data: